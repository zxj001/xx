package org.apache.spark.sql.catalyst.expressions;
/**
 * User-defined function.
 * @param dataType  Return type of function.
 */
public  class ScalaUdf extends org.apache.spark.sql.catalyst.expressions.Expression implements scala.Product, scala.Serializable {
  public  java.lang.Object function () { throw new RuntimeException(); }
  public  org.apache.spark.sql.catalyst.types.DataType dataType () { throw new RuntimeException(); }
  public  scala.collection.Seq<org.apache.spark.sql.catalyst.expressions.Expression> children () { throw new RuntimeException(); }
  // not preceding
  public   ScalaUdf (java.lang.Object function, org.apache.spark.sql.catalyst.types.DataType dataType, scala.collection.Seq<org.apache.spark.sql.catalyst.expressions.Expression> children) { throw new RuntimeException(); }
  public  boolean nullable () { throw new RuntimeException(); }
  public  java.lang.String toString () { throw new RuntimeException(); }
  /** This method has been generated by this script
   * <p>
   (1 to 22).map { x =>
   val anys = (1 to x).map(x => "Any").reduce(_ + ", " + _)
   val evals = (0 to x - 1).map(x => s"    ScalaReflection.convertToScala(children($x).eval(input), children($x).dataType)").reduce(_ + ",\n    " + _)
   * <p>
   s"""
   case $x =>
   function.asInstanceOf[($anys) => Any](
   $evals)
   """
   }.foreach(println)
   * <p>
   */
  public  Object eval (org.apache.spark.sql.catalyst.expressions.Row input) { throw new RuntimeException(); }
}
